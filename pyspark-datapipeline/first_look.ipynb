{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "                     .master(\"local[*]\")\n",
    "                     .appName(\"test\")\n",
    "                     .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../docker-datapipeline/yellow_tripdata_2021-01.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "           .option(\"header\", \"true\")\n",
    "           .csv(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show csv data and schema. Everything is string for spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(VendorID,StringType,true),StructField(tpep_pickup_datetime,StringType,true),StructField(tpep_dropoff_datetime,StringType,true),StructField(passenger_count,StringType,true),StructField(trip_distance,StringType,true),StructField(RatecodeID,StringType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,StringType,true),StructField(DOLocationID,StringType,true),StructField(payment_type,StringType,true),StructField(fare_amount,StringType,true),StructField(extra,StringType,true),StructField(mta_tax,StringType,true),StructField(tip_amount,StringType,true),StructField(tolls_amount,StringType,true),StructField(improvement_surcharge,StringType,true),StructField(total_amount,StringType,true),StructField(congestion_surcharge,StringType,true)))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.show()\n",
    "# df.head(5)\n",
    "\n",
    "\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 5 data and save to head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type command in git bash\n",
    "# head docker-datapipeline/yellow_tripdata_2021-01.csv > head.csv | mv head.csv pyspark-datapipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv with pandas and see the datatype. Pandas is infering the datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "tpep_pickup_datetime      object\n",
       "tpep_dropoff_datetime     object\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "RatecodeID                 int64\n",
       "store_and_fwd_flag        object\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "payment_type               int64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount               int64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pandas = pd.read_csv(\"head.csv\")\n",
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe from pandas. We can see that dtypes is vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2021-01-01 00:30:10|  2021-01-01 00:36:12|              1|          2.1|         1|                 N|         142|          43|           2|        8.0|  3.0|    0.5|       0.0|           0|                  0.3|        11.8|                 2.5|\n",
      "|       1| 2021-01-01 00:51:20|  2021-01-01 00:52:19|              1|          0.2|         1|                 N|         238|         151|           2|        3.0|  0.5|    0.5|       0.0|           0|                  0.3|         4.3|                 0.0|\n",
      "|       1| 2021-01-01 00:43:30|  2021-01-01 01:11:06|              1|         14.7|         1|                 N|         132|         165|           1|       42.0|  0.5|    0.5|      8.65|           0|                  0.3|       51.95|                 0.0|\n",
      "|       1| 2021-01-01 00:15:48|  2021-01-01 00:31:01|              0|         10.6|         1|                 N|         138|         132|           1|       29.0|  0.5|    0.5|      6.05|           0|                  0.3|       36.35|                 0.0|\n",
      "|       2| 2021-01-01 00:31:49|  2021-01-01 00:48:21|              1|         4.94|         1|                 N|          68|          33|           1|       16.5|  0.5|    0.5|      4.06|           0|                  0.3|       24.36|                 2.5|\n",
      "|       1| 2021-01-01 00:16:29|  2021-01-01 00:24:30|              1|          1.6|         1|                 N|         224|          68|           1|        8.0|  3.0|    0.5|      2.35|           0|                  0.3|       14.15|                 2.5|\n",
      "|       1| 2021-01-01 00:00:28|  2021-01-01 00:17:28|              1|          4.1|         1|                 N|          95|         157|           2|       16.0|  0.5|    0.5|       0.0|           0|                  0.3|        17.3|                 0.0|\n",
      "|       1| 2021-01-01 00:12:29|  2021-01-01 00:30:34|              1|          5.7|         1|                 N|          90|          40|           2|       18.0|  3.0|    0.5|       0.0|           0|                  0.3|        21.8|                 2.5|\n",
      "|       1| 2021-01-01 00:39:16|  2021-01-01 01:00:13|              1|          9.1|         1|                 N|          97|         129|           4|       27.5|  0.5|    0.5|       0.0|           0|                  0.3|        28.8|                 0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create schema from known datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField(\"VendorID\", types.IntegerType(), True),\n",
    "    types.StructField(\"tpep_pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"tpep_dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"passenger_count\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_distance\", types.FloatType(), True),\n",
    "    types.StructField(\"RatecodeID\", types.IntegerType(), True),\n",
    "    types.StructField(\"store_and_fwd_flag\", types.StringType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"payment_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"fare_amount\", types.FloatType(), True),\n",
    "    types.StructField(\"extra\", types.FloatType(), True),\n",
    "    types.StructField(\"mta_tax\", types.FloatType(), True),\n",
    "    types.StructField(\"tip_amount\", types.FloatType(), True),\n",
    "    types.StructField(\"tolls_amount\", types.IntegerType(), True),\n",
    "    types.StructField(\"improvement_surcharge\", types.FloatType(), True),\n",
    "    types.StructField(\"total_amount\", types.FloatType(), True),\n",
    "    types.StructField(\"congestion_surcharge\", types.FloatType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv again. Now we specify the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "           .option(\"header\", \"true\")\n",
    "           .schema(schema)\n",
    "           .csv(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatype is fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2021, 1, 1, 0, 30, 10), tpep_dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 36, 12), passenger_count=1, trip_distance=2.0999999046325684, RatecodeID=1, store_and_fwd_flag='N', PULocationID=142, DOLocationID=43, payment_type=2, fare_amount=8.0, extra=3.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0, improvement_surcharge=0.30000001192092896, total_amount=11.800000190734863, congestion_surcharge=2.5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of read one large file. We can split the file into smaller parts to utilize spark clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data into spark format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"yellow_tripdata.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the kernel and try to reopen the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "                     .master(\"local[*]\")\n",
    "                     .appName(\"test\")\n",
    "                     .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", True).parquet(\"yellow_tripdata.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2021, 1, 10, 12, 32, 3), tpep_dropoff_datetime=datetime.datetime(2021, 1, 10, 12, 43, 36), passenger_count=1, trip_distance=3.5, RatecodeID=1, store_and_fwd_flag='N', PULocationID=79, DOLocationID=236, payment_type=1, fare_amount=12.0, extra=2.5, mta_tax=0.5, tip_amount=3.049999952316284, tolls_amount=0, improvement_surcharge=0.30000001192092896, total_amount=18.350000381469727, congestion_surcharge=2.5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(VendorID=None, sum(VendorID)=None, sum(passenger_count)=None, sum(trip_distance)=2917624.442051178, sum(RatecodeID)=None, sum(PULocationID)=14892901, sum(DOLocationID)=13331869, sum(payment_type)=None, sum(fare_amount)=2565865.076589197, sum(extra)=79782.82001562417, sum(mta_tax)=48730.0, sum(tip_amount)=161767.29994092882, sum(tolls_amount)=426, sum(improvement_surcharge)=29501.701172292233, sum(total_amount)=3051485.7303704023, sum(congestion_surcharge)=51804.75)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(df.VendorID).sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = ps.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-10 12:32:03</td>\n",
       "      <td>2021-01-10 12:43:36</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-05 10:26:12</td>\n",
       "      <td>2021-01-05 10:42:45</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-06 13:25:45</td>\n",
       "      <td>2021-01-06 13:34:09</td>\n",
       "      <td>1</td>\n",
       "      <td>2.74</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>170</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-04 08:19:46</td>\n",
       "      <td>2021-01-04 08:30:33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>237</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-10 11:14:50</td>\n",
       "      <td>2021-01-10 11:47:14</td>\n",
       "      <td>1</td>\n",
       "      <td>6.93</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>113</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.759998</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  congestion_surcharge\n",
       "0         1  2021-01-10 12:32:03   2021-01-10 12:43:36                1           3.50           1                  N            79           236             1         12.0    2.5      0.5        3.05             0                    0.3     18.350000                   2.5\n",
       "1         2  2021-01-05 10:26:12   2021-01-05 10:42:45                1           3.70           1                  N           234            33             2         14.5    0.0      0.5        0.00             0                    0.3     17.799999                   2.5\n",
       "2         2  2021-01-06 13:25:45   2021-01-06 13:34:09                1           2.74           1                  N           170           263             1          9.5    0.0      0.5        2.00             0                    0.3     14.800000                   2.5\n",
       "3         2  2021-01-04 08:19:46   2021-01-04 08:30:33                1           2.25           1                  N           237           239             2         10.0    0.0      0.5        0.00             0                    0.3     13.300000                   2.5\n",
       "4         2  2021-01-10 11:14:50   2021-01-10 11:47:14                1           6.93           1                  N           113            37             1         26.5    0.0      0.5        5.96             0                    0.3     35.759998                   2.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 1369765|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"yellow_taxi\")\n",
    "spark.sql(\"SELECT count(*) from yellow_taxi LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL alternative of `.nunique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------------------------+\n",
      "|count(DISTINCT tpep_pickup_datetime)|count(DISTINCT VendorID)|\n",
      "+------------------------------------+------------------------+\n",
      "|                              939018|                       2|\n",
      "+------------------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(DISTINCT tpep_pickup_datetime), count(DISTINCT VendorID) FROM yellow_taxi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|\n",
      "+--------+--------------------+\n",
      "|       2| 2021-01-09 13:28:04|\n",
      "|       2| 2021-01-07 08:17:14|\n",
      "|       1| 2021-01-04 16:12:44|\n",
      "|       2| 2021-01-07 21:22:01|\n",
      "|       2| 2021-01-01 17:20:53|\n",
      "|       1| 2021-01-08 08:44:50|\n",
      "|       2| 2021-01-06 11:40:29|\n",
      "|       2| 2021-01-06 11:25:51|\n",
      "|       1| 2021-01-03 12:23:20|\n",
      "|       1| 2021-01-04 09:08:34|\n",
      "|       2| 2021-01-04 07:22:22|\n",
      "|       1| 2021-01-01 22:04:01|\n",
      "|       1| 2021-01-02 10:39:49|\n",
      "|       2| 2021-01-05 22:16:08|\n",
      "|       2| 2021-01-06 16:00:12|\n",
      "|       2| 2021-01-02 17:53:51|\n",
      "|       2| 2021-01-06 14:31:16|\n",
      "|       2| 2021-01-06 11:51:16|\n",
      "|       2| 2021-01-07 20:46:19|\n",
      "|       2| 2021-01-05 17:49:28|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT VendorID, tpep_pickup_datetime FROM yellow_taxi\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL alternative of `.value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|VendorID| count|\n",
      "+--------+------+\n",
      "|    null| 98352|\n",
      "|       1|410762|\n",
      "|       2|860651|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT VendorID, count(*) as count FROM yellow_taxi GROUP BY VendorID\").show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17d5de0220e859e87431ff8652880fbd136352a03b5e7c5f75a47ca716f5e564"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
